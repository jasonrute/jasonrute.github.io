# Portfolio

Here are some cool things I have done.

## AI for theorem proving - Lean GPT-f and Proof Artifact Co-Training

<iframe width="560" height="315" src="https://www.youtube.com/embed/EXpmbAfBNnw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

I, in collaboration with other researchers, helped develop an AI to prove mathematical theorems.

The [Lean theorem prover](https://leanprover-community.github.io) is a tool to formally verify mathematical theorems down to the axioms of mathematics.  This provides an electronic repository of mathematics, where each proof has been certified for correctness.  Developing such formal mathematical libraries are labor intensive undertakings, requiring thousands of person-hours.  

This project was two-fold.  First, we developed two machine learning datasets for Lean:
* [jasonrute/lean_proof_recording: Proof recording for Lean 3](https://github.com/jasonrute/lean_proof_recording)
* [jesse-michael-han/lean-step-public: Proof artifact co-training for Lean](https://github.com/jesse-michael-han/lean-step-public)

Next, with, OpenAI, we trained a large language model on this data using a novel approach called Proof Artifact Co-Training.  The resulting tool, Lean GPT-f, is a practical assistant to Lean users.  Also, we show our model is capable of proving entire theorems by itself.  See the [Proof Artifact Co-training for Theorem Proving with Language Models](https://arxiv.org/abs/2102.06203) for details.

## Classifying call center calls

<img src="canstockphoto2706055.jpg" alt="Solving Rubik’s cube via deep reinforcement learning" height="300"/>

In contract work for an outbound call center, I used supervised learning to automatically classify phone call transcripts into a half dozen industry categories ("voicemail", "not interested", "wrong number", etc.)  I achieved an accuracy of 84%, exceeding the companies expectations, which will free up agents from having to manually label calls.

Specifically, I started with transcripts of the phone calls generated by a third party service.  I used a "bag-of-words" approach where I converted each transcript into a collection of pairs of adjacent words weighted by their uniqueness to the message.  Then I trained a classifier via multiclass logistic regression with regularization.  This resulted in a simple, interpretable, fast, and robust classifier which can quickly classify the phone call transcripts.

## Solving Rubik’s cube via deep reinforcement learning

<a href="https://github.com/jasonrute/puzzle_cube"><img src="https://foter.com/photos/395/rubik-cube-cube-game-puzzle-rubik-toy-square.jpg" alt="Solving Rubik’s cube via deep reinforcement learning" height="300"/></a>

I used a variation of Deepmind's AlphaZero algorithm for Go (and Chess) to learn to solve a Rubik's cube with using no prior knowledge.

Specifically, I use a deep 3D convolutional neural network to compute a policy (next best move) and valuation (shortest number of moves to solution).  This network is trained via reinforcment learning, where the algorithm uses Monte Carlo tree search to find for a solution to a randomly shuffled cube.  These solutions are used, in turn, to train the next generation of the network.  This new network is used to guide the next round of Monte Carlo tree search, and so on.

See [here](https://github.com/jasonrute/puzzle_cube) for more.

## Training a neural network to play a racing game

<a href="https://github.com/jasonrute/csb_neural_network"><img src="bot_nn_genetic.gif" alt="Training a neural network to play a racing game" height="300"/></a>

In [Coders Strike Back](https://www.codingame.com/multiplayer/bot-programming/coders-strike-back) one programs a bot to race through an open course, touching each checkpoint in order.  Using reinforcement learning I have trained a bot to be able to quickly race through the course even after being knocked around by the other bots.

Specifically, I use a small feed-forward neural network to compute a policy (next best move).  This network is trained via reinforcment learning, where an optimization algorithm uses Monte Carlo search (specifically a form of evolutionary algorithm) to search for the most optimal path in randomly generated race courses.  These solutions are, in turn, used to train the next generation of network.  This new network is used to seed the next round of optimization, and so on.

See [here](https://github.com/jasonrute/csb_neural_network) for more.
